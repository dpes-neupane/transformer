{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torchtext.transforms as T\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def loadFiles(file):\n",
    "    with open(file, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "    print(\"The size of the dataset is:\", len(data))\n",
    "    return data\n",
    "\n",
    "\n",
    "def separateData(data):\n",
    "    X = data[:, 0]\n",
    "    y = data[:, 1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is: 10000\n"
     ]
    }
   ],
   "source": [
    "data = loadFiles(r'./english-german-both.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng, germ = separateData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLongestSequence(sentList):\n",
    "    return max(len(seq.split()) for seq in sentList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scotty/.local/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "/home/scotty/.local/lib/python3.10/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "enTokenizer = get_tokenizer('spacy', language='en')\n",
    "deTokenizer = get_tokenizer('spacy', language='de')\n",
    "def yieldTokensEn(data):\n",
    "    for text in data:\n",
    "        yield enTokenizer(text[:-1])\n",
    "\n",
    "def yieldTokensDe(data):\n",
    "    \n",
    "    for text in data:\n",
    "        yield deTokenizer(text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabEn = build_vocab_from_iterator(yieldTokensEn(eng), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"], special_first=True)\n",
    "vocabDe = build_vocab_from_iterator(yieldTokensDe(germ), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"], special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "textPipelineEn = lambda x: vocabEn(enTokenizer(x))\n",
    "textPipelineDe = lambda x: vocabDe(deTokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainEn, testEn, trainDe, testDe = train_test_split(eng, germ, test_size=0.1)\n",
    "trainEn, valEn, trainDe, valDe = train_test_split(eng, germ, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_IDX = vocabEn(['<pad>'])[0]\n",
    "SOS_IDX = vocabEn(['<sos>'])\n",
    "EOS_IDX = vocabEn(['<eos>'])\n",
    "print(PAD_IDX)\n",
    "print(SOS_IDX)\n",
    "print(EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def generateData(eng, deu):\n",
    "    data = []\n",
    "    for en, de in zip(eng, deu):\n",
    "        enTensor = torch.tensor(textPipelineEn(en[:-1]), dtype=torch.long)\n",
    "        deTensor = torch.tensor(textPipelineDe(de[:-1]), dtype=torch.long)\n",
    "        data.append((enTensor, deTensor))\n",
    "    return data\n",
    "\n",
    "\n",
    "trainData = generateData(trainEn, trainDe)\n",
    "valData = generateData(valEn, valDe)         \n",
    "testData = generateData(testEn, testDe)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "    \n",
    "def generateBatch(data_batch):\n",
    "  de_batch, en_batch = [], []\n",
    "  # print(data_batch)\n",
    "  for (de_item, en_item) in data_batch:\n",
    "    de_batch.append(torch.cat([torch.tensor(SOS_IDX), de_item, torch.tensor(EOS_IDX)], dim=0))\n",
    "    en_batch.append(torch.cat([torch.tensor(SOS_IDX), en_item, torch.tensor(EOS_IDX)], dim=0))\n",
    "  deLength = len(de_batch)\n",
    "  batch = pad_sequence(en_batch + de_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "  en_batch, de_batch = batch[:deLength], batch[deLength:]\n",
    "  return de_batch, en_batch\n",
    "\n",
    "\n",
    "trainIter = DataLoader(trainData, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generateBatch)\n",
    "valIter =  DataLoader(valData, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generateBatch)\n",
    "testIter = DataLoader(testData, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generateBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The english has 2594 words.\n",
      "The german has 4167 words.\n"
     ]
    }
   ],
   "source": [
    "from model.transformer import Transformer\n",
    "from model.positenc import PositionalEncodingTorch\n",
    "from torch.nn import Embedding, Module, Linear\n",
    "\n",
    "EMB_DIM = 128\n",
    "HEADS = 8\n",
    "LINEAR_DIM = 2048\n",
    "DROPOUT = 0.1\n",
    "LAYERS = 6\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.98\n",
    "EPSILON = 10**-9\n",
    "ENG_VOCAB_LEN = vocabEn.__len__()\n",
    "DE_VOCAB_LEN = vocabDe.__len__()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"The english has {ENG_VOCAB_LEN} words.\")\n",
    "print(f\"The german has {DE_VOCAB_LEN} words.\")\n",
    "\n",
    "EN_MAX_SEQ_LEN, DE_MAX_SEQ_LEN = findLongestSequence(eng) + 2 , findLongestSequence(germ) + 2\n",
    "\n",
    "#mask for the decoder\n",
    "def createMask(x):\n",
    "    batch, seq_length, _ = x.size()\n",
    "    mask = torch.ones((batch, seq_length, seq_length)).to(device)\n",
    "    mask = torch.tril(mask, diagonal=0)\n",
    "    return mask\n",
    "\n",
    "def createMaskGen(x):\n",
    "    x = x.unsqueeze(1)\n",
    "    batch, _, seq_length = x.size()\n",
    "    mask = torch.ones((batch, 1, seq_length)).to(device)\n",
    "    maskR = torch.logical_and(mask, x)\n",
    "    maskC = torch.logical_and(x.transpose(-1, 1), mask.transpose(-1, 1))\n",
    "    mask = torch.multiply(maskR, maskC)\n",
    "    return mask\n",
    "    \n",
    "\n",
    "\n",
    "class TransformerModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embEn = Embedding(ENG_VOCAB_LEN, EMB_DIM)\n",
    "        self.embDe = Embedding(DE_VOCAB_LEN, EMB_DIM)\n",
    "        self.positEn = PositionalEncodingTorch(EN_MAX_SEQ_LEN, EMB_DIM)\n",
    "        self.positDe = PositionalEncodingTorch(DE_MAX_SEQ_LEN, EMB_DIM)\n",
    "        self.transformer = Transformer(LAYERS, EMB_DIM, EMB_DIM, HEADS, LINEAR_DIM, DROPOUT)\n",
    "        self.linear = Linear(EMB_DIM, DE_VOCAB_LEN)\n",
    "        \n",
    "    def forward(self, eng, de):\n",
    "        mask1 = createMaskGen(eng)\n",
    "        eng = self.embEn(eng)\n",
    "        eng = self.positEn(eng)\n",
    "        mask = createMaskGen(de)\n",
    "        de = self.embDe(de)\n",
    "        de = self.positDe(de)\n",
    "        mask2 = createMask(de)\n",
    "        mask2 = torch.logical_and(mask, mask2)\n",
    "        dec = self.transformer(eng, de, mask1, mask2)\n",
    "        lin = self.linear(dec)    \n",
    "        return lin\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLRScheduler(object):\n",
    "    def __init__(self,  warmup_steps:int=10, d_model:int=512):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    \n",
    "    def __call__(self, epoch):\n",
    "        epoch = epoch + 1\n",
    "        minimum = min(epoch**-0.5, epoch * ((self.warmup_steps) ** (-1.5)))\n",
    "        return (self.d_model**-0.5 ) * minimum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(prediction, target):\n",
    "    padding_mask = torch.logical_not(torch.eq(target, torch.tensor(0)))\n",
    "    accuracy = torch.eq(target, torch.argmax(prediction, axis=2))\n",
    "    accuracy = torch.logical_and(padding_mask, accuracy)\n",
    "    accuracy = accuracy.type(torch.float32)\n",
    "    padding_mask = padding_mask.type(torch.float32)\n",
    "    return torch.sum(accuracy) / torch.sum(padding_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(model, testIter, loss, device):\n",
    "    lossPerBatch = []\n",
    "    accPerBatch = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (X, y) in enumerate(testIter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            out = model(X[:, 1:], y[:, :-1])\n",
    "            l = loss(out.contiguous().view(-1, 4167), y[:, 1:].contiguous().view(-1))\n",
    "            a = calculateAccuracy(out, y[:, 1:])\n",
    "            lossPerBatch.append(l.item())\n",
    "            accPerBatch.append(a.item())\n",
    "        meanLoss = sum(lossPerBatch)/len(lossPerBatch)\n",
    "    return lossPerBatch, meanLoss, accPerBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "model = TransformerModel()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), betas=(BETA_1, BETA_2), eps=EPSILON)\n",
    "loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "scheduler = TransformerLRScheduler(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 141/141 [00:39<00:00,  3.55batches/s, accuracy=0.37, loss=4.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 4.494223594665527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 141/141 [00:39<00:00,  3.60batches/s, accuracy=0.35, loss=4.34] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 4.386409789323807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 141/141 [00:38<00:00,  3.65batches/s, accuracy=0.376, loss=4.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 4.139525979757309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 141/141 [00:39<00:00,  3.55batches/s, accuracy=0.432, loss=3.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.951369196176529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 141/141 [00:40<00:00,  3.52batches/s, accuracy=0.459, loss=3.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.7955708354711533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 141/141 [00:38<00:00,  3.62batches/s, accuracy=0.464, loss=3.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.634869337081909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 141/141 [00:39<00:00,  3.61batches/s, accuracy=0.48, loss=3.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.471206620335579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 141/141 [00:37<00:00,  3.72batches/s, accuracy=0.587, loss=2.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.3126397281885147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 141/141 [00:36<00:00,  3.91batches/s, accuracy=0.484, loss=3.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.1896308958530426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 141/141 [00:36<00:00,  3.82batches/s, accuracy=0.528, loss=2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 3.0579340159893036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 141/141 [00:39<00:00,  3.55batches/s, accuracy=0.577, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.900737091898918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 141/141 [00:38<00:00,  3.64batches/s, accuracy=0.609, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.7769332230091095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 141/141 [00:36<00:00,  3.88batches/s, accuracy=0.661, loss=1.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.6011139899492264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 141/141 [00:36<00:00,  3.85batches/s, accuracy=0.708, loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.4490253776311874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 141/141 [00:36<00:00,  3.89batches/s, accuracy=0.685, loss=1.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.376742497086525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 141/141 [00:38<00:00,  3.71batches/s, accuracy=0.739, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.29269852489233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 141/141 [00:38<00:00,  3.69batches/s, accuracy=0.809, loss=1.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.2394701167941093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 141/141 [00:39<00:00,  3.61batches/s, accuracy=0.773, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.3154958710074425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 141/141 [00:37<00:00,  3.80batches/s, accuracy=0.812, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.3351793065667152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 141/141 [00:38<00:00,  3.68batches/s, accuracy=0.773, loss=1.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.255977638065815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 141/141 [00:35<00:00,  3.93batches/s, accuracy=0.746, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.2758749276399612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 141/141 [00:35<00:00,  3.93batches/s, accuracy=0.802, loss=0.72] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.415500044822693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 141/141 [00:37<00:00,  3.79batches/s, accuracy=0.81, loss=0.792] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.479667142033577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 141/141 [00:40<00:00,  3.51batches/s, accuracy=0.818, loss=0.637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.5352026373147964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 141/141 [00:39<00:00,  3.59batches/s, accuracy=0.776, loss=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.556930035352707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 141/141 [00:39<00:00,  3.53batches/s, accuracy=0.724, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.567691072821617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 141/141 [00:39<00:00,  3.58batches/s, accuracy=0.822, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.6552927643060684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 141/141 [00:39<00:00,  3.57batches/s, accuracy=0.76, loss=0.842] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.68728506565094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 141/141 [00:39<00:00,  3.60batches/s, accuracy=0.805, loss=0.762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.6593070924282074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 141/141 [00:40<00:00,  3.47batches/s, accuracy=0.8, loss=0.822]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.7017649710178375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 141/141 [00:42<00:00,  3.35batches/s, accuracy=0.848, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss is: 2.7665096819400787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32:  79%|███████▉  | 112/141 [00:31<00:08,  3.57batches/s, accuracy=0.789, loss=0.707]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m                         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logs_dic\n\u001b[0;32m---> 54\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainIter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestIter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalIter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainIter, testIter, epochs, loss, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     35\u001b[0m     tepoch\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39ml\u001b[38;5;241m.\u001b[39mitem(), accuracy\u001b[38;5;241m=\u001b[39macc\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     36\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 37\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m valLoss, meanValLoss, valAcc \u001b[38;5;241m=\u001b[39m validateModel(model, testIter, loss\u001b[38;5;241m=\u001b[39mloss, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe validation loss is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeanValLoss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:434\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 434\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def train(model, trainIter, \n",
    "          testIter=None, \n",
    "          epochs=None, \n",
    "          loss=None, \n",
    "          optimizer=None, \n",
    "          device=device, \n",
    "          scheduler=None):\n",
    "    # model.to(device)\n",
    "    # pbar = trange(epochs, desc=\"Epochs \", unit=\"batches\")\n",
    "    # with tqdm(trainIter, unit=\"epochs\") as tepoch:\n",
    "    logs_dic = {\n",
    "        \"valildationLoss\": [],\n",
    "        \"trainingLoss\" : [],\n",
    "        \"validationAccuracy\": [],\n",
    "        \"trainingAccuracy\": []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        trainLossPerBatch = []\n",
    "        trainAccuracyPerBatch = []\n",
    "        with tqdm(trainIter, unit=\"batches\") as tepoch:\n",
    "            for i, (X,y) in enumerate(tepoch):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                out = model(X[:, 1:], y[:, :-1])\n",
    "                l = loss(out.contiguous().view(-1, 4167), y[:, 1:].contiguous().view(-1))\n",
    "                acc = calculateAccuracy(out, y[:, 1:])\n",
    "                trainLossPerBatch.append(l.item())\n",
    "                trainAccuracyPerBatch.append(acc.item())\n",
    "                tepoch.set_description(f\"Epoch {epoch + 1}\")            \n",
    "                tepoch.set_postfix(loss=l.item(), accuracy=acc.item())\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "            valLoss, meanValLoss, valAcc = validateModel(model, testIter, loss=loss, device=device)\n",
    "            print(f\"The validation loss is: {meanValLoss}\")\n",
    "            logs_dic[\"valildationLoss\"].append(valLoss)\n",
    "            logs_dic[\"trainingLoss\"].append(trainLossPerBatch)\n",
    "            logs_dic[\"trainingAccuracy\"].append(trainAccuracyPerBatch)\n",
    "            logs_dic[\"validationAccuracy\"].append(valAcc)\n",
    "            # print(f\"Epoch: {epoch+1}     loss: {l}\")\n",
    "            if scheduler:\n",
    "                if scheduler.__module__ == lr_scheduler.__name__:\n",
    "                    scheduler.step()\n",
    "                else:\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        lr = scheduler(epoch)\n",
    "                        param_group['lr'] = lr\n",
    "                \n",
    "    return logs_dic\n",
    "history = train(model, trainIter, testIter=valIter, epochs=1000, loss=loss, optimizer=optimizer, device=device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# lr = TransformerLRScheduler(1000)\n",
    "# plt.plot([i for i in range(5000)], [lr(i) for i in range(5000)])\n",
    "# plt.grid()\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel(\"Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.save_dict(), './')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
